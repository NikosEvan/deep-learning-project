# deep-learning-project

1. Αρχικα αρχισα να αλλαζω τις παραμετρους σχεδον τυχαια ενω στη συνεχεια πηρα βοηθεια (για το ποιες αλλαγες φερνουν συνηθως θετικα αποτελεσματα) απο google και chatgpt.
2. 
Ο πιανακας με τις αλλαγες και τα αντιστοιχα accuracies:

![image](https://github.com/user-attachments/assets/e05954ab-4eb8-4b14-9e5f-c77f465003ea)

Η ακριβεια βελτιωθηκε απο 0.9358 σε 0.9641.


2. Για τη βελτιωση του accuracy του νευρωνικου δικτυου εκανα κανονικοποιηση (normalization) των layers των νευρωνων πριν "περασουν" απο τη συναρτηση κανονικοποιησης.

Αccuracy (πριν την κανονικοποιηση): 0.9641

Αccuracy (μετα την κανονικοποιηση): 0.9719 

Αλλαξα και learning rate σε 0.009 και epochs σε 13 και πετυχα accuracy: 0.9790


3. a. Τα δεδομενα MNIST δεν ειναι τελεια για την εκπαιδευση ενος μοντελου γιατι τα ψηφια ειναι σχετικα ευκρινη, χωρις χρωματα και αλλες περιεργες παραμορφωσεις. Οποτε δεν ειναι τα καταλληλα δεδομενα για ενα πρακτικο στον "εξω" κοσμο μοντελο, αλλα ισως ειναι καταλληλο για απλουστερα προβληματα.
   b. Οχι, τα pixels στις ακρες, αυτα που αναπαριστουν απλα το φοντο δεν συνεισφερουν τοσο οσο τα ιδια τα pixels που "δομουν" τον καθε αριθμο.
   c. Αξιζει να χρησιμοποιηθουν βαθια νευρωνικα δικτυα οταν αρχικα εχουμε διαθεσουν τους απαραιτητους υπολογιστικους πορους και οταν το προβλημα ειναι τοσο συνθετο και τα δεδομενα τοσο πολλα που αλλοι μεθοδοι μηχανικης μαθησης δεν μπορουν να πετυχουν μεγαλη ακριβεια.
   d. Ναι η βαθια μαθηση μπορει να χρησιμοποιηθει και στους τρεις κλαδους αναλογα με το ποια θελουμε να ειναι η χρηση του μοντελου που θα εκπαιδευσουμε.
